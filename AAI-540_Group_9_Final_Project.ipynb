{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "145112d5-c3d6-4e97-8d00-8ae81e3676e5",
   "metadata": {},
   "source": [
    "## AAI-540 ML OPS\n",
    "## Final Project : YELP REVIEWS \n",
    "## Team ::: Group 9 \n",
    "## 1) Sandeep Kumar Jakkaraju\n",
    "## 2) Harish Archarya\n",
    "## 3) Angshuman Roy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0f83c",
   "metadata": {},
   "source": [
    "# üìì Yelp Reviews: Integrated Pipeline (Supervised Rating + KMeans Analysis)\n",
    "\n",
    "This single notebook **merges** the two prior notebooks into one coherent workflow that **ends in a trained, evaluated ML model** for **predicting star ratings** from review **Text**.  \n",
    "It also includes an **optional KMeans analysis** section (from your previous KMeans notebook) for exploration‚Äî**it does not alter the supervised pipeline** unless you choose to.\n",
    "\n",
    "**What you get end-to-end:**\n",
    "- Data Sources\n",
    "- Data Engineering (Processing)\n",
    "- Feature Engineering (TF‚ÄëIDF)\n",
    "- **Supervised Model Training & Evaluation** (Logistic Regression multiclass)\n",
    "- (Optional) **KMeans** clustering for insight\n",
    "- (Optional) Feature Store ingest\n",
    "- (Optional) Deployment + Monitoring\n",
    "- CI/CD‚Äëfriendly layout via helper scripts\n",
    "\n",
    "> Columns used: **`Text`** (features) and **`Stars (Review)`** (label in 1‚Äì5).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af6e15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9b18173c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region: eu-central-1\n",
      "role: arn:aws:iam::495599743560:role/WNTMLSagemakerTrainingRole\n",
      "bucket: sagemaker-eu-central-1-495599743560\n",
      "prefix: yelp-integrated-pipeline\n"
     ]
    }
   ],
   "source": [
    "import os, boto3, sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sess   = Session()\n",
    "role   = get_execution_role()\n",
    "bucket = sess.default_bucket()                # <<< change if you want a fixed bucket\n",
    "prefix = \"yelp-integrated-pipeline\"           # <<< tweak as needed\n",
    "SRC_DIR = \"src\"\n",
    "os.makedirs(SRC_DIR, exist_ok=True)\n",
    "\n",
    "print(\"region:\", region)\n",
    "print(\"role:\", role)\n",
    "print(\"bucket:\", bucket)\n",
    "print(\"prefix:\", prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ccfaa9",
   "metadata": {},
   "source": [
    "## üß© Write Helper Scripts (Processing, Training, Inference, Evaluation)\n",
    "\n",
    "We generate consistent helper scripts under `src/` so SageMaker jobs can run them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6709f7bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All helper scripts written successfully:\n",
      "  - inference_supervised.py\n",
      "  - processing_supervised.py\n",
      "  - training_supervised.py\n",
      "  - evaluation_supervised.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Directory for helper scripts\n",
    "SRC_DIR = Path(\"src_scripts\")\n",
    "SRC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Processing Script\n",
    "# -------------------------------------------------------------\n",
    "processing_script = \"\"\"\\\n",
    "import argparse, os, re, string, time, hashlib, boto3, joblib\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "\n",
    "def basic_clean(s):\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\\\s+\", \" \", s)\n",
    "    s = s.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    return s.strip()\n",
    "\n",
    "def mk_review_id(text):\n",
    "    return hashlib.sha1(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def build_fs_table(df, text_col, label_col):\n",
    "    event_time = int(time.time())\n",
    "    out = pd.DataFrame({\n",
    "        \"review_id\": df[text_col].astype(str).map(mk_review_id),\n",
    "        \"event_time\": event_time,\n",
    "        \"num_chars\": df[text_col].str.len(),\n",
    "        \"num_words\": df[text_col].str.split().map(len),\n",
    "        \"avg_word_len\": df[text_col].str.split().map(lambda w: np.mean([len(x) for x in w]) if w else 0),\n",
    "        \"stars\": df[label_col].astype(int)\n",
    "    })\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--input_data\", required=True)\n",
    "    p.add_argument(\"--output_data\", required=True)\n",
    "    p.add_argument(\"--text_column\", default=\"Text\")\n",
    "    p.add_argument(\"--label_column\", default=\"Stars (Review)\")\n",
    "    p.add_argument(\"--max_features\", type=int, default=30000)\n",
    "    p.add_argument(\"--test_size\", type=float, default=0.2)\n",
    "    p.add_argument(\"--random_state\", type=int, default=42)\n",
    "    args = p.parse_args()\n",
    "\n",
    "    os.makedirs(\"/opt/ml/processing/input\", exist_ok=True)\n",
    "    os.makedirs(\"/opt/ml/processing/output\", exist_ok=True)\n",
    "    os.makedirs(\"/opt/ml/processing/temp\", exist_ok=True)\n",
    "\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    bucket = args.input_data.split(\"/\")[2]\n",
    "    key = \"/\".join(args.input_data.split(\"/\")[3:])\n",
    "    local_csv = \"/opt/ml/processing/input/raw.csv\"\n",
    "    s3.download_file(bucket, key, local_csv)\n",
    "\n",
    "    df = pd.read_csv(local_csv)\n",
    "    df[args.text_column] = df[args.text_column].astype(str).map(basic_clean)\n",
    "    df = df[df[args.text_column].str.len() > 0]\n",
    "\n",
    "    y = pd.to_numeric(df[args.label_column], errors=\"coerce\").clip(1, 5).astype(int)\n",
    "    X_train_txt, X_test_txt, y_train, y_test = train_test_split(\n",
    "        df[args.text_column], y, test_size=args.test_size, random_state=args.random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    tfidf = TfidfVectorizer(max_features=args.max_features, ngram_range=(1,2))\n",
    "    X_train = tfidf.fit_transform(X_train_txt)\n",
    "    X_test = tfidf.transform(X_test_txt)\n",
    "\n",
    "    model_dir = \"/opt/ml/processing/output/model\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    joblib.dump(tfidf, os.path.join(model_dir, \"tfidf.joblib\"))\n",
    "    joblib.dump(tfidf, os.path.join(\"/tmp\", \"tfidf.joblib\"))\n",
    "        \n",
    "\n",
    "\n",
    "    sparse.save_npz(\"/opt/ml/processing/output/X_train.npz\", X_train)\n",
    "    sparse.save_npz(\"/opt/ml/processing/output/X_test.npz\", X_test)\n",
    "    np.save(\"/opt/ml/processing/output/y_train.npy\", y_train)\n",
    "    np.save(\"/opt/ml/processing/output/y_test.npy\", y_test)\n",
    "\n",
    "    fs_df = build_fs_table(df, args.text_column, args.label_column)\n",
    "    fs_df.to_csv(\"/opt/ml/processing/output/features.csv\", index=False)\n",
    "\n",
    "    out_b = args.output_data.split(\"/\")[2]\n",
    "    out_p = \"/\".join(args.output_data.split(\"/\")[3:])\n",
    "    s3.upload_file(os.path.join(model_dir, \"tfidf.joblib\"), out_b, f\"{out_p}/tfidf.joblib\")\n",
    "    for f in [\"X_train.npz\", \"X_test.npz\", \"y_train.npy\", \"y_test.npy\", \"features.csv\"]:\n",
    "        s3.upload_file(f\"/opt/ml/processing/output/{f}\", out_b, f\"{out_p}/{f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Training Script\n",
    "# -------------------------------------------------------------\n",
    "training_script = \"\"\"\\\n",
    "import argparse, os, boto3, joblib, numpy as np, shutil\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def main():\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--C\", type=float, default=1.0)\n",
    "    p.add_argument(\"--max_iter\", type=int, default=1000)\n",
    "    p.add_argument(\"--processed_data\", required=True)\n",
    "    p.add_argument(\"--model_dir\", default=os.environ.get(\"SM_MODEL_DIR\", \"/opt/ml/model\"))\n",
    "    args = p.parse_args()\n",
    "\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    bucket = args.processed_data.split(\"/\")[2]\n",
    "    prefix = \"/\".join(args.processed_data.split(\"/\")[3:])\n",
    "\n",
    "    tmp_dir = \"/tmp/\"\n",
    "    os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "    # Download training artifacts\n",
    "    X_local = \"/tmp/X_train.npz\"\n",
    "    y_local = \"/tmp/y_train.npy\"\n",
    "    tfidf_local = \"/tmp/tfidf.joblib\"\n",
    "    s3.download_file(bucket, f\"{prefix}/X_train.npz\", X_local)\n",
    "    s3.download_file(bucket, f\"{prefix}/y_train.npy\", y_local)\n",
    "    s3.download_file(bucket, f\"{prefix}/tfidf.joblib\", tfidf_local)\n",
    "\n",
    "    X_train = sparse.load_npz(X_local)\n",
    "    y_train = np.load(y_local)\n",
    "    tfidf = joblib.load(tfidf_local)\n",
    "\n",
    "    clf = LogisticRegression(C=args.C, max_iter=args.max_iter, solver=\"saga\", n_jobs=-1, multi_class=\"multinomial\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "     # Save model and vectorizer directly to SM_MODEL_DIR\n",
    "    os.makedirs(args.model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    tfidf_path = os.path.join(args.model_dir, \"tfidf.joblib\")\n",
    "    \n",
    "    joblib.dump(clf, model_path)\n",
    "    joblib.dump(tfidf, tfidf_path)\n",
    "    \n",
    "    print(f\"‚úÖ Saved model to {model_path}\")\n",
    "    print(f\"‚úÖ Saved TF-IDF vectorizer to {tfidf_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Inference Script\n",
    "# -------------------------------------------------------------\n",
    "inference_script = \"\"\"\\\n",
    "import os, json, joblib, shutil\n",
    "\n",
    "def find_model_file(filename):\n",
    "    opt_path = os.path.join(\"/opt/ml/model\", filename)\n",
    "    tmp_path = os.path.join(\"/tmp/\", filename)\n",
    "    if os.path.exists(opt_path):\n",
    "        return opt_path\n",
    "    elif os.path.exists(tmp_path):\n",
    "        return tmp_path\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Missing file: {filename}\")\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    os.makedirs(\"/tmp/\", exist_ok=True)\n",
    "    src_model = find_model_file(\"model.joblib\")\n",
    "    src_vect = find_model_file(\"tfidf.joblib\")\n",
    "    shutil.copy(src_model, \"/tmp/model.joblib\")\n",
    "    shutil.copy(src_vect, \"/tmp/tfidf.joblib\")\n",
    "    model = joblib.load(\"/tmp/model.joblib\")\n",
    "    vect = joblib.load(\"/tmp/tfidf.joblib\")\n",
    "    return {\"model\": model, \"vectorizer\": vect}\n",
    "\n",
    "def input_fn(request_body, request_content_type=\"application/json\"):\n",
    "    if request_content_type == \"application/json\":\n",
    "        payload = json.loads(request_body)\n",
    "        texts = payload.get(\"texts\", [])\n",
    "        if isinstance(texts, str): texts = [texts]\n",
    "        return texts\n",
    "    elif request_content_type == \"text/csv\":\n",
    "        return [line for line in request_body.splitlines() if line.strip()]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {request_content_type}\")\n",
    "\n",
    "def predict_fn(inputs, model):\n",
    "    vect = model[\"vectorizer\"]\n",
    "    clf = model[\"model\"]\n",
    "    X = vect.transform(inputs)\n",
    "    preds = clf.predict(X).tolist()\n",
    "    proba = clf.predict_proba(X).tolist() if hasattr(clf, \"predict_proba\") else None\n",
    "    return {\"predictions\": preds, \"probabilities\": proba}\n",
    "\n",
    "def output_fn(prediction, accept=\"application/json\"):\n",
    "    return json.dumps(prediction), \"application/json\"\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Evaluation Script\n",
    "# -------------------------------------------------------------\n",
    "evaluation_script = \"\"\"\\\n",
    "import argparse, os, json, boto3, joblib, numpy as np, tarfile\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "def extract_model_tar(model_artifact, local_dir):\n",
    "    os.makedirs(local_dir, exist_ok=True)\n",
    "    tar_path = os.path.join(local_dir, \"model.tar.gz\")\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    b = model_artifact.split(\"/\")[2]\n",
    "    k = \"/\".join(model_artifact.split(\"/\")[3:])\n",
    "    s3.download_file(b, k, tar_path)\n",
    "    with tarfile.open(tar_path) as t:\n",
    "        t.extractall(local_dir)\n",
    "    return os.path.join(local_dir, \"model.joblib\")\n",
    "\n",
    "def main():\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--processed_data\", required=True)\n",
    "    p.add_argument(\"--model_artifact\", required=True)\n",
    "    p.add_argument(\"--output\", default=\"/opt/ml/processing/output/evaluation\")\n",
    "    args = p.parse_args()\n",
    "\n",
    "    os.makedirs(args.output, exist_ok=True)\n",
    "    model_path = extract_model_tar(args.model_artifact, \"/opt/ml/processing/temp/model\")\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    pb = args.processed_data.split(\"/\")[2]\n",
    "    pp = \"/\".join(args.processed_data.split(\"/\")[3:])\n",
    "    Xte = \"/opt/ml/processing/temp/X_test.npz\"\n",
    "    yte = \"/opt/ml/processing/temp/y_test.npy\"\n",
    "    os.makedirs(os.path.dirname(Xte), exist_ok=True)\n",
    "    s3.download_file(pb, f\"{pp}/X_test.npz\", Xte)\n",
    "    s3.download_file(pb, f\"{pp}/y_test.npy\", yte)\n",
    "\n",
    "    X_test = sparse.load_npz(Xte)\n",
    "    y_test = np.load(yte)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = float(accuracy_score(y_test, y_pred))\n",
    "    f1m = float(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    results = {\"accuracy\": acc, \"f1_macro\": f1m, \"confusion_matrix\": cm, \"classification_report\": report}\n",
    "    with open(os.path.join(args.output, \"evaluation.json\"), \"w\") as f:\n",
    "        json.dump(results, f)\n",
    "    print(json.dumps(results, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5Ô∏è‚É£ Write all scripts to src_scripts/\n",
    "# -------------------------------------------------------------\n",
    "(SRC_DIR / \"processing_supervised.py\").write_text(processing_script.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "(SRC_DIR / \"training_supervised.py\").write_text(training_script.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "(SRC_DIR / \"inference_supervised.py\").write_text(inference_script.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "(SRC_DIR / \"evaluation_supervised.py\").write_text(evaluation_script.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"‚úÖ All helper scripts written successfully:\")\n",
    "for p in SRC_DIR.iterdir():\n",
    "    print(\"  -\", p.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6ca8a-2da5-485e-91a8-18cec7eb2483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85c82e30",
   "metadata": {},
   "source": [
    "## üì¶ Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "edb7dac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW: s3://sagemaker-eu-central-1-495599743560/yelp-integrated-pipeline/raw/yelp_reviews.csv\n",
      "PROC: s3://sagemaker-eu-central-1-495599743560/yelp-integrated-pipeline/processed\n"
     ]
    }
   ],
   "source": [
    "raw_s3 = f\"s3://{bucket}/{prefix}/raw/yelp_reviews.csv\"   # Must contain 'Text' and 'Stars (Review)'\n",
    "proc_s3 = f\"s3://{bucket}/{prefix}/processed\"\n",
    "print(\"RAW:\", raw_s3)\n",
    "print(\"PROC:\", proc_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ce016",
   "metadata": {},
   "source": [
    "## üßπ Processing (TF‚ÄëIDF + Splits + features.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c6982483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "INFO:sagemaker:Creating processing-job with name sagemaker-scikit-learn-2025-10-20-11-25-10-201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............\n",
      "..Processing job complete.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "import sagemaker\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", region, version=\"1.2-1\"),\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    command=[\"python3\"],\n",
    ")\n",
    "\n",
    "script_processor.run(\n",
    "    code=os.path.join(SRC_DIR, \"processing_supervised.py\"),\n",
    "    arguments=[\n",
    "        \"--input_data\", raw_s3,\n",
    "        \"--output_data\", proc_s3,\n",
    "        \"--text_column\", \"Text\",\n",
    "        \"--label_column\", \"Stars (Review)\",\n",
    "        \"--max_features\", \"30000\",\n",
    "        \"--test_size\", \"0.2\",\n",
    "        \"--random_state\", \"42\",\n",
    "    ],\n",
    "    inputs=[],\n",
    "    outputs=[],\n",
    ")\n",
    "print(\"Processing job complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9099e",
   "metadata": {},
   "source": [
    "## üî¨ Optional: KMeans Analysis (from the unsupervised notebook)\n",
    "\n",
    "This section reproduces a KMeans view purely for **insight**. It downloads TF‚ÄëIDF artifacts from S3,\n",
    "trains KMeans **locally in the notebook kernel** on a sample (or full set if memory allows), and prints\n",
    "top terms per cluster. It **does not modify** the supervised training inputs unless you explicitly change that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "895eb3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.2.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.2.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: pizza, the, the pizza, and, was, is, of, to, it, crust\n",
      "Cluster 1: ramen, the, and, is, broth, was, noodles, to, pork, the ramen\n",
      "Cluster 2: the, and, was, menu, to, the menu, on, food, of, is\n",
      "Cluster 3: you, the, and, to, is, if, if you, your, are, for\n",
      "Cluster 4: the, to, and, back, was, go, this, place, it, for\n",
      "Cluster 5: the, to, and, it, was, that, for, of, my, me\n",
      "Cluster 6: the, and, to, of, we, was, in, with, were, for\n",
      "Cluster 7: the, is, and, place, this, of, in, to, you, this place\n",
      "Cluster 8: great, and, the, food, friendly, service, staff, is, very, friendly staff\n",
      "Cluster 9: the, was, and, it, of, to, with, we, for, were\n",
      "Cluster 10: thai, pad, pad thai, the, and, thai food, was, food, is, curry\n",
      "Cluster 11: chicken, the, was, and, the chicken, it, of, to, fried, with\n",
      "Cluster 12: the, is, and, are, of, to, food, always, in, they\n",
      "Cluster 13: sushi, the, and, is, was, of, the sushi, to, roll, rolls\n",
      "Cluster 14: good, the, and, is, but, pretty, food, are, for, service\n",
      "Cluster 15: the, and, was, we, had, were, amazing, had the, for, great\n",
      "Cluster 16: mi, banh, banh mi, the, bao, pork, and, fries, mi boys, vietnamese\n",
      "Cluster 17: was, the, and, it, it was, had, good, but, for, of\n",
      "Cluster 18: the, and, of, is, their, to, for, they, in, are\n",
      "Cluster 19: we, the, and, was, to, our, were, us, we were, for\n"
     ]
    }
   ],
   "source": [
    "import os, io, joblib, boto3, numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Download TF-IDF model and training matrix\n",
    "s3 = boto3.client(\"s3\")\n",
    "b = proc_s3.split(\"/\")[2]; p = \"/\".join(proc_s3.split(\"/\")[3:])\n",
    "local_tfidf = \"tfidf.joblib\"\n",
    "local_Xtr   = \"X_train.npz\"\n",
    "s3.download_file(b, f\"{p}/tfidf.joblib\", local_tfidf)\n",
    "s3.download_file(b, f\"{p}/X_train.npz\", local_Xtr)\n",
    "\n",
    "tfidf = joblib.load(local_tfidf)\n",
    "X_train = sparse.load_npz(local_Xtr)\n",
    "\n",
    "# Fit KMeans on a sub-sample if needed (to keep speed/memory in check)\n",
    "n_samples = min(X_train.shape[0], 20000)   # <<< adjust\n",
    "if n_samples < X_train.shape[0]:\n",
    "    idx = np.random.RandomState(42).choice(X_train.shape[0], size=n_samples, replace=False)\n",
    "    X_km = X_train[idx]\n",
    "else:\n",
    "    X_km = X_train\n",
    "\n",
    "k = 20  # <<< number of clusters\n",
    "km = KMeans(n_clusters=k, max_iter=300, n_init=\"auto\", random_state=42)\n",
    "km.fit(X_km)\n",
    "\n",
    "# Show top terms per cluster\n",
    "terms = tfidf.get_feature_names_out()\n",
    "centers = km.cluster_centers_\n",
    "for i in range(k):\n",
    "    top_idx = centers[i].argsort()[-10:][::-1]\n",
    "    top_terms = [terms[j] for j in top_idx]\n",
    "    print(f\"Cluster {i}: {', '.join(top_terms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cd68dd",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Feature Store (Optional)\n",
    "\n",
    "Create a Feature Group from the engineered features (`features.csv`) and ingest to **Online + Offline**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e6d5e77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Feature Group Creation...\n",
      "Waiting for Feature Group Creation...\n",
      "Waiting for Feature Group Creation...\n",
      "Feature Group created: yelp-review-features-20-11-28-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.feature_store.feature_group:Started ingesting index 2977 to 5954\n",
      "INFO:sagemaker.feature_store.feature_group:Started ingesting index 8931 to 11906\n",
      "INFO:sagemaker.feature_store.feature_group:Started ingesting index 5954 to 8931\n",
      "INFO:sagemaker.feature_store.feature_group:Started ingesting index 0 to 2977\n",
      "INFO:sagemaker.feature_store.feature_group:Successfully ingested row 5954 to 8931\n",
      "INFO:sagemaker.feature_store.feature_group:Successfully ingested row 2977 to 5954\n",
      "INFO:sagemaker.feature_store.feature_group:Successfully ingested row 8931 to 11906\n",
      "INFO:sagemaker.feature_store.feature_group:Successfully ingested row 0 to 2977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FS ingestion complete: yelp-review-features-20-11-28-06\n"
     ]
    }
   ],
   "source": [
    "import io, time, pandas as pd\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# Load features.csv\n",
    "s3 = boto3.client(\"s3\", region_name=region)\n",
    "pb = proc_s3.split(\"/\")[2]\n",
    "pp = \"/\".join(proc_s3.split(\"/\")[3:])\n",
    "feat_key = f\"{pp}/features/features.csv\"\n",
    "obj = s3.get_object(Bucket=pb, Key=feat_key)\n",
    "fs_df = pd.read_csv(io.BytesIO(obj[\"Body\"].read()))\n",
    "\n",
    "# Enforce FS-friendly dtypes\n",
    "fs_df[\"review_id\"]  = fs_df[\"review_id\"].astype(str)\n",
    "fs_df[\"event_time\"] = pd.to_numeric(fs_df[\"event_time\"], errors=\"coerce\").astype(\"float64\")\n",
    "fs_df[\"num_chars\"]  = pd.to_numeric(fs_df[\"num_chars\"], errors=\"coerce\").astype(\"int64\")\n",
    "fs_df[\"num_words\"]  = pd.to_numeric(fs_df[\"num_words\"], errors=\"coerce\").astype(\"int64\")\n",
    "fs_df[\"avg_word_len\"] = pd.to_numeric(fs_df[\"avg_word_len\"], errors=\"coerce\").astype(\"float64\")\n",
    "fs_df[\"stars\"] = pd.to_numeric(fs_df[\"stars\"], errors=\"coerce\").astype(\"int64\")\n",
    "\n",
    "fg_name = \"yelp-review-features-\" + strftime(\"%d-%H-%M-%S\", gmtime())\n",
    "fg = FeatureGroup(name=fg_name, sagemaker_session=sess)\n",
    "fg.load_feature_definitions(data_frame=fs_df)\n",
    "fg.create(\n",
    "    s3_uri=f\"s3://{bucket}/{prefix}/feature-store\",\n",
    "    record_identifier_name=\"review_id\",\n",
    "    event_time_feature_name=\"event_time\",\n",
    "    role_arn=role,\n",
    "    enable_online_store=True,\n",
    ")\n",
    "\n",
    "def wait_fg(feature_group):\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation...\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise RuntimeError(f\"Feature Group not created. Status={status}\")\n",
    "    print(\"Feature Group created:\", feature_group.name)\n",
    "\n",
    "wait_fg(fg)\n",
    "\n",
    "# Ingest to both stores (SDK enums vary by version, handle broadly)\n",
    "try:\n",
    "    from sagemaker.feature_store.inputs import TargetStore\n",
    "    opt = None\n",
    "    for a,b in [(\"ONLINE\",\"OFFLINE\"), (\"ONLINE_STORE\",\"OFFLINE_STORE\"), (\"OnlineStore\",\"OfflineStore\")]:\n",
    "        if hasattr(TargetStore, a) and hasattr(TargetStore, b):\n",
    "            opt = [getattr(TargetStore,a), getattr(TargetStore,b)]\n",
    "            break\n",
    "    if opt:\n",
    "        fg.ingest(data_frame=fs_df, max_workers=4, wait=True, target_stores=opt)\n",
    "    else:\n",
    "        fg.ingest(data_frame=fs_df, max_workers=4, wait=True)\n",
    "except Exception:\n",
    "    fg.ingest(data_frame=fs_df, max_workers=4, wait=True)\n",
    "\n",
    "print(\"FS ingestion complete:\", fg_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd37c5c0",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Supervised Training ‚Äî Logistic Regression (Multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c65818f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: yelp-rating-train-2025-10-20-11-28-53-296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-20 11:28:54 Starting - Starting the training job...\n",
      "2025-10-20 11:29:08 Starting - Preparing the instances for training...\n",
      "2025-10-20 11:29:56 Downloading - Downloading the training image........\u001b[34m/miniconda3/lib/python3.9/site-packages/sagemaker_containers/_server.py:22: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,531 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,536 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,539 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,556 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,801 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,804 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,823 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,825 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,843 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,846 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,862 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.large\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"C\": \"1.0\",\n",
      "        \"max_iter\": \"1000\",\n",
      "        \"processed_data\": \"\\\"s3://sagemaker-eu-central-1-495599743560/yelp-integrated-pipeline/processed\\\"\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.large\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"yelp-rating-train-2025-10-20-11-28-53-296\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-495599743560/yelp-rating-train-2025-10-20-11-28-53-296/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"training_supervised\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"training_supervised.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"C\":\"1.0\",\"max_iter\":\"1000\",\"processed_data\":\"\\\"s3://sagemaker-eu-central-1-495599743560/yelp-integrated-pipeline/processed\\\"\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=training_supervised.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.large\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=training_supervised\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-central-1-495599743560/yelp-rating-train-2025-10-20-11-28-53-296/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.large\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"C\":\"1.0\",\"max_iter\":\"1000\",\"processed_data\":\"\\\"s3://sagemaker-eu-central-1-495599743560/yelp-integrated-pipeline/processed\\\"\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"yelp-rating-train-2025-10-20-11-28-53-296\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-495599743560/yelp-rating-train-2025-10-20-11-28-53-296/source/sourcedir.tar.gz\",\"module_name\":\"training_supervised\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"training_supervised.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"-C\",\"1.0\",\"--max_iter\",\"1000\",\"--processed_data\",\"\\\"s3://sagemaker-eu-central-1-495599743560/yelp-integrated-pipeline/processed\\\"\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_C=1.0\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_ITER=1000\u001b[0m\n",
      "\u001b[34mSM_HP_PROCESSED_DATA=\"s3://sagemaker-eu-central-1-495599743560/yelp-integrated-pipeline/processed\"\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python39.zip:/miniconda3/lib/python3.9:/miniconda3/lib/python3.9/lib-dynload:/miniconda3/lib/python3.9/site-packages:/miniconda3/lib/python3.9/site-packages/setuptools/_vendor\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python training_supervised.py -C 1.0 --max_iter 1000 --processed_data \"s3://sagemaker-eu-central-1-495599743560/yelp-integrated-pipeline/processed\"\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,863 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:04,863 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mReceived arguments: Namespace(C=1.0, max_iter=1000, processed_data='s3://sagemaker-eu-central-1-495599743560/yelp-integrated-pipeline/processed', model_dir='/opt/ml/model')\u001b[0m\n",
      "\u001b[34mDownloading training data from s3://sagemaker-eu-central-1-495599743560/yelp-integrated-pipeline/processed/...\u001b[0m\n",
      "\u001b[34mTraining Logistic Regression model...\u001b[0m\n",
      "\u001b[34mModel saved to /opt/ml/model/model.joblib\u001b[0m\n",
      "\u001b[34m2025-10-20 11:31:07,380 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-10-20 11:31:25 Training - Training image download completed. Training in progress.\n",
      "2025-10-20 11:31:25 Uploading - Uploading generated training model\n",
      "2025-10-20 11:31:25 Completed - Training job completed\n",
      "Training seconds: 115\n",
      "Billable seconds: 115\n",
      "Model artifact: s3://sagemaker-eu-central-1-495599743560/yelp-rating-train-2025-10-20-11-28-53-296/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "est = SKLearn(\n",
    "    entry_point=\"training_supervised.py\",\n",
    "    source_dir=\"src\",  # Folder containing the script\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    framework_version=\"1.2-1\",\n",
    "    py_version=\"py3\",\n",
    "    base_job_name=\"yelp-rating-train\",\n",
    "    model_dir=\"/tmp\"\n",
    ")\n",
    "\n",
    "est.set_hyperparameters(\n",
    "    processed_data=proc_s3,   # e.g. 's3://my-bucket/yelp/processed'\n",
    "    C=1.0,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "est.fit()\n",
    "\n",
    "model_artifact = est.model_data\n",
    "print(\"Model artifact:\", model_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3252e9",
   "metadata": {},
   "source": [
    "## üìä Evaluation ‚Äî Accuracy & Macro F1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee040f08-e6d5-45b7-9c96-097c14d8c02e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "eproc = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", region, version=\"1.2-1\"),\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    command=[\"python3\"],\n",
    "    base_job_name=\"yelp-rating-eval\"\n",
    ")\n",
    "\n",
    "eproc.run(\n",
    "    code=os.path.join(SRC_DIR, \"evaluation_supervised.py\"),\n",
    "    arguments=[\n",
    "        \"--processed_data\", proc_s3,\n",
    "        \"--model_artifact\", model_artifact,\n",
    "        \"--output\", \"/opt/ml/processing/evaluation\"\n",
    "    ],\n",
    "    inputs=[], outputs=[]\n",
    ")\n",
    "print(\"Evaluation job complete ‚Äî check CloudWatch logs for metrics (and evaluation.json).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0871363f-0859-4126-9c59-d8ad779994e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_scripts\n",
      "s3://sagemaker-eu-central-1-495599743560/yelp-rating-train-2025-10-20-11-28-53-296/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(SRC_DIR)\n",
    "print(model_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa72dc",
   "metadata": {},
   "source": [
    "## üöÄ Deployment ‚Äî Real-time Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "476ba454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-scikit-learn-2025-10-20-11-57-07-239\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-scikit-learn-2025-10-20-11-57-07-903\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-scikit-learn-2025-10-20-11-57-07-903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!‚úÖ Endpoint name: sagemaker-scikit-learn-2025-10-20-11-57-07-903\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Directories\n",
    "# -------------------------------------------------------------\n",
    "SRC_DIR = Path(\"src_scripts\")\n",
    "SRC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Model directory (where artifacts are saved during training)\n",
    "# -------------------------------------------------------------\n",
    "MODEL_DIR = \"/tmp/\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# SageMaker Model Definition\n",
    "# -------------------------------------------------------------\n",
    "sk_model = SKLearnModel(\n",
    "    model_data=model_artifact,  # e.g., \"s3://<bucket>/<prefix>/model.tar.gz\"\n",
    "    entry_point=os.path.join(SRC_DIR, \"inference_supervised.py\"),\n",
    "    framework_version=\"1.2-1\",\n",
    "    role=role,\n",
    "    env={\n",
    "        # Add custom environment variables here\n",
    "        \"TFIDF_S3_URI\": f\"{proc_s3}/tfidf.joblib\",\n",
    "        \"MODEL_DIR\": MODEL_DIR   # ‚úÖ New param for inference script\n",
    "    }\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Deployment\n",
    "# -------------------------------------------------------------\n",
    "predictor = sk_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    data_capture_config=DataCaptureConfig(\n",
    "        enable_capture=True,\n",
    "        sampling_percentage=100,\n",
    "        destination_s3_uri=f\"s3://{bucket}/{prefix}/datacapture/\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Endpoint name:\", predictor.endpoint_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0581972d",
   "metadata": {},
   "source": [
    "### üîé Quick Probe\n",
    "### Predict for few reviews text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ddb33caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [5, 2], \"probabilities\": [[0.00928452605770668, 0.007932621288482582, 0.006602629918243063, 0.15182515104165684, 0.8243550716939109], [0.11524447288971221, 0.5435778677067528, 0.1977567268045214, 0.08386447610440634, 0.0595564564946072]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName='sagemaker-scikit-learn-2025-10-20-11-57-07-903',\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps({\n",
    "        \"texts\": [\n",
    "            \"Amazing service and delicious food. Will come back!\",\n",
    "            \"The burger was dry and the fries were soggy. Not impressed.\"\n",
    "        ]\n",
    "    })\n",
    ")\n",
    "\n",
    "print(response['Body'].read().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52725db0",
   "metadata": {},
   "source": [
    "## üìà Monitoring ‚Äî Baseline & Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "884bec1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating processing-job with name yelp-rating-monitor-2025-10-20-12-05-30-479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................\u001b[34m2025-10-20 12:08:05.692618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:05.692654: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:07.349500: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:07.349547: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:07.349578: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-122-34.eu-central-1.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:07.349896: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:09,244 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:eu-central-1:495599743560:processing-job/yelp-rating-monitor-2025-10-20-12-05-30-479', 'ProcessingJobName': 'yelp-rating-monitor-2025-10-20-12-05-30-479', 'Environment': {'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '048819808253.dkr.ecr.eu-central-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-eu-central-1-495599743560/yelp-integrated-pipeline/raw/yelp_reviews.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinitionInput': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-eu-central-1-495599743560/yelp-integrated-pipeline/monitoring/baseline', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.large', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'NetworkConfig': {'VpcConfig': None, 'EnableNetworkIsolation': False, 'EnableInterContainerTrafficEncryption': False}, 'RoleArn': 'arn:aws:iam::495599743560:role/WNTMLSagemakerTrainingRole', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:09,244 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:09,245 - __main__ - INFO - categorical_drift_method:None\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:09,245 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"exclude_features_attribute\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"data_quality_monitoring_config\": {\"evaluate_constraints\": \"Enabled\", \"emit_metrics\": \"Enabled\", \"datatype_check_threshold\": 1.0, \"domain_content_threshold\": 1.0, \"distribution_constraints\": {\"perform_comparison\": \"Enabled\", \"comparison_threshold\": 0.1, \"comparison_method\": \"Robust\", \"categorical_comparison_threshold\": 0.1, \"categorical_drift_method\": \"LInfinity\"}}, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:09,245 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:09,245 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:09,561 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:09,561 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:09,562 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'current_instance_type': 'ml.m5.large', 'current_group_name': 'homogeneousCluster', 'hosts': ['algo-1'], 'instance_groups': [{'instance_group_name': 'homogeneousCluster', 'instance_type': 'ml.m5.large', 'hosts': ['algo-1']}], 'network_interface_name': 'eth0', 'topology': None}\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:09,574 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:09,575 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:09,575 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:11,274 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.122.34\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/\u001b[0m\n",
      "\u001b[34mhadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_392\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:11,311 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:11,317 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-aff7a9a1-198a-4589-8f74-8d14613fdd93\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,310 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,332 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,334 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,338 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,357 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,357 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,357 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,357 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,414 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,435 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,435 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,439 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,443 INFO blockmanagement.BlockManager: The block deletion will start around 2025 Oct 20 12:08:12\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,445 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,445 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,448 INFO util.GSet: 2.0% max memory 1.4 GB = 28.4 MB\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,448 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,480 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,484 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,484 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,484 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,484 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,485 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,485 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,485 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,485 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,485 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,485 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,485 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,553 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,553 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,553 INFO util.GSet: 1.0% max memory 1.4 GB = 14.2 MB\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,553 INFO util.GSet: capacity      = 2^21 = 2097152 entries\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,554 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,554 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,554 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,555 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,560 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,565 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,565 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,566 INFO util.GSet: 0.25% max memory 1.4 GB = 3.6 MB\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,566 INFO util.GSet: capacity      = 2^19 = 524288 entries\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,576 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,577 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,577 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,580 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,581 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,584 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,584 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,584 INFO util.GSet: 0.029999999329447746% max memory 1.4 GB = 437.0 KB\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,584 INFO util.GSet: capacity      = 2^16 = 65536 entries\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,616 INFO namenode.FSImage: Allocated new BlockPoolId: BP-2124656089-10.0.122.34-1760962092607\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,635 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,649 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,775 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,797 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,804 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.122.34\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:12,814 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:14,878 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:14,878 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:16,992 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:16,993 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:19,140 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:19,140 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:21,375 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:21,376 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:23,765 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:23,766 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:33,774 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:36,765 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:37,309 INFO Main: Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:37,355 INFO Main: Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:37,377 INFO FileUtil: Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,160 INFO spark.SparkContext: Running Spark version 3.3.0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,200 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,201 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,203 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,205 INFO spark.SparkContext: Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,243 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 5664, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,263 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,265 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,354 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,354 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,354 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,355 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,355 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:38,931 INFO util.Utils: Successfully started service 'sparkDriver' on port 40525.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:39,005 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:39,066 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:39,109 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:39,110 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:39,163 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:39,220 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-232cb2df-c49e-4433-aead-114500a5a961\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:39,245 INFO memory.MemoryStore: MemoryStore started with capacity 1458.6 MiB\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:39,306 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:39,364 INFO spark.SparkContext: Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.0.122.34:40525/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1760962118152\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:40,158 INFO client.RMProxy: Connecting to ResourceManager at /10.0.122.34:8032\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:41,086 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:41,086 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:41,095 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (7724 MB per container)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:41,096 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:41,096 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:41,097 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:41,107 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:41,213 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:43,693 INFO yarn.Client: Uploading resource file:/tmp/spark-3c6cd3c1-72e8-4e21-a617-1e0cdf056413/__spark_libs__7084128009603289835.zip -> hdfs://10.0.122.34/user/root/.sparkStaging/application_1760962100621_0001/__spark_libs__7084128009603289835.zip\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:46,175 INFO yarn.Client: Uploading resource file:/tmp/spark-3c6cd3c1-72e8-4e21-a617-1e0cdf056413/__spark_conf__2317145894087043912.zip -> hdfs://10.0.122.34/user/root/.sparkStaging/application_1760962100621_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:46,235 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:46,235 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:46,236 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:46,236 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:46,236 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:46,273 INFO yarn.Client: Submitting application application_1760962100621_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:46,493 INFO impl.YarnClientImpl: Submitted application application_1760962100621_0001\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:47,500 INFO yarn.Client: Application report for application_1760962100621_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:47,518 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: [Mon Oct 20 12:08:46 +0000 2025] Scheduler has assigned a container for AM, waiting for AM container to be launched\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1760962126377\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1760962100621_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:48,522 INFO yarn.Client: Application report for application_1760962100621_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:49,526 INFO yarn.Client: Application report for application_1760962100621_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:50,529 INFO yarn.Client: Application report for application_1760962100621_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:51,535 INFO yarn.Client: Application report for application_1760962100621_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:52,540 INFO yarn.Client: Application report for application_1760962100621_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:53,544 INFO yarn.Client: Application report for application_1760962100621_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:54,368 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1760962100621_0001), /proxy/application_1760962100621_0001\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:54,547 INFO yarn.Client: Application report for application_1760962100621_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:54,548 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.122.34\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1760962126377\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1760962100621_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:54,550 INFO cluster.YarnClientSchedulerBackend: Application application_1760962100621_0001 has started running.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:54,609 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41057.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:54,609 INFO netty.NettyBlockTransferService: Server created on 10.0.122.34:41057\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:54,611 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:54,634 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.122.34, 41057, None)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:54,645 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.122.34:41057 with 1458.6 MiB RAM, BlockManagerId(driver, 10.0.122.34, 41057, None)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:54,661 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.122.34, 41057, None)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:54,662 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.122.34, 41057, None)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:54,886 INFO util.log: Logging initialized @20694ms to org.sparkproject.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2025-10-20 12:08:56,525 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:01,207 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.122.34:41786) with ID 1,  ResourceProfileId 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:01,483 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:44185 with 2.8 GiB RAM, BlockManagerId(1, algo-1, 44185, None)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:10,032 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:10,401 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:10,497 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:10,508 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-3.3.0/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:12,342 INFO datasources.InMemoryFileIndex: It took 134 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:12,679 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 416.9 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,189 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.1 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,194 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.122.34:41057 (size: 39.1 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,201 INFO spark.SparkContext: Created broadcast 0 from csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,717 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,725 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,731 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,827 INFO spark.SparkContext: Starting job: csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,853 INFO scheduler.DAGScheduler: Got job 0 (csv at DatasetReader.scala:99) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,854 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at DatasetReader.scala:99)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,855 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,856 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,880 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,945 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,952 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,955 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.122.34:41057 (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,956 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,975 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:13,976 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:14,024 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4625 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:14,487 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:44185 (size: 4.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:15,474 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:44185 (size: 39.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:15,931 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1925 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:15,940 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:15,957 INFO scheduler.DAGScheduler: ResultStage 0 (csv at DatasetReader.scala:99) finished in 2.012 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:15,962 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:15,966 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:15,968 INFO scheduler.DAGScheduler: Job 0 finished: csv at DatasetReader.scala:99, took 2.140678 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:16,242 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:44185 in memory (size: 4.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:16,257 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.122.34:41057 in memory (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:19,273 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:19,275 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:19,278 INFO datasources.FileSourceStrategy: Output Data Schema: struct<Number of Records: string, Address: string, Business Id (Review): string, Business Id: string, Category: string ... 23 more fields>\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:19,768 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 416.5 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:19,800 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.1 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:19,805 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.122.34:41057 (size: 39.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:19,812 INFO spark.SparkContext: Created broadcast 2 from head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:19,876 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 7062042 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,009 INFO spark.SparkContext: Starting job: head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,013 INFO scheduler.DAGScheduler: Got job 1 (head at DataAnalyzer.scala:124) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,014 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (head at DataAnalyzer.scala:124)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,014 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,018 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,031 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,170 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 20.0 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,174 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,176 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.122.34:41057 (size: 8.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,178 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,179 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,180 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,184 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:20,249 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:44185 (size: 8.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:21,715 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-1:44185 (size: 39.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:22,901 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on algo-1:44185 (size: 8.8 MiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:23,220 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3038 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:23,221 INFO scheduler.DAGScheduler: ResultStage 1 (head at DataAnalyzer.scala:124) finished in 3.187 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:23,227 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:23,227 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:23,228 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:23,228 INFO scheduler.DAGScheduler: Job 1 finished: head at DataAnalyzer.scala:124, took 3.217973 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:23,805 INFO codegen.CodeGenerator: Code generated in 488.698252 ms\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,632 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,798 INFO scheduler.DAGScheduler: Registering RDD 16 (collect at AnalysisRunner.scala:326) as input to shuffle 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,802 INFO scheduler.DAGScheduler: Got map stage job 2 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,803 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,803 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,806 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,808 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,842 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 116.8 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,845 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,846 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.122.34:41057 (size: 35.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,851 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,854 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,854 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,862 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:24,900 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:44185 (size: 35.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:26,944 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2084 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:26,944 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:26,947 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326) finished in 2.132 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:26,957 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:26,958 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:26,959 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:26,960 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,232 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,245 INFO scheduler.DAGScheduler: Got job 3 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,245 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,245 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,245 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,254 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,304 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 169.7 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,306 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 46.7 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,308 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.122.34:41057 (size: 46.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,309 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,311 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,311 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,314 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,350 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:44185 (size: 46.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:27,420 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.122.34:41786\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,069 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 756 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,069 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,070 INFO scheduler.DAGScheduler: ResultStage 4 (collect at AnalysisRunner.scala:326) finished in 0.790 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,072 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,072 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,073 INFO scheduler.DAGScheduler: Job 3 finished: collect at AnalysisRunner.scala:326, took 0.840605 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,147 INFO codegen.CodeGenerator: Code generated in 53.952942 ms\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,414 INFO scheduler.DAGScheduler: Registering RDD 24 (collect at AnalysisRunner.scala:326) as input to shuffle 1\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,415 INFO scheduler.DAGScheduler: Got map stage job 4 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,415 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 5 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,415 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,418 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,419 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,470 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 85.8 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,473 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,474 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.122.34:41057 (size: 28.1 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,479 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,488 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,489 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,489 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.122.34:41057 in memory (size: 8.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,492 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,494 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:44185 in memory (size: 8.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,526 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:44185 (size: 28.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,542 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:44185 in memory (size: 35.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,544 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.122.34:41057 in memory (size: 35.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,587 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.122.34:41057 in memory (size: 46.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,620 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:44185 in memory (size: 46.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,868 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 376 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,868 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,869 INFO scheduler.DAGScheduler: ShuffleMapStage 5 (collect at AnalysisRunner.scala:326) finished in 0.447 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,870 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,871 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,871 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,871 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,927 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,929 INFO scheduler.DAGScheduler: Got job 5 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,929 INFO scheduler.DAGScheduler: Final stage: ResultStage 7 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,929 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,930 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,932 INFO scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[27] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,946 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 170.5 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,949 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 47.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,950 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.122.34:41057 (size: 47.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,952 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,952 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[27] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,953 INFO cluster.YarnScheduler: Adding task set 7.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,955 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,976 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:44185 (size: 47.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:28,993 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.122.34:41786\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,143 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 188 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,143 INFO cluster.YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,144 INFO scheduler.DAGScheduler: ResultStage 7 (collect at AnalysisRunner.scala:326) finished in 0.210 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,146 INFO scheduler.DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,146 INFO cluster.YarnScheduler: Killing all running tasks in stage 7: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,147 INFO scheduler.DAGScheduler: Job 5 finished: collect at AnalysisRunner.scala:326, took 0.219404 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,297 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,301 INFO scheduler.DAGScheduler: Registering RDD 35 (countByKey at ColumnProfiler.scala:592) as input to shuffle 2\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,302 INFO scheduler.DAGScheduler: Got job 6 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,302 INFO scheduler.DAGScheduler: Final stage: ResultStage 9 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,302 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,302 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 8)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,304 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[35] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,315 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 32.9 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,317 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,318 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.122.34:41057 (size: 14.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,318 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,319 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[35] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,319 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,321 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:29,333 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:44185 (size: 14.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,546 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 2226 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,547 INFO scheduler.DAGScheduler: ShuffleMapStage 8 (countByKey at ColumnProfiler.scala:592) finished in 2.242 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,547 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,547 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,547 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,547 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 9)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,548 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,548 INFO scheduler.DAGScheduler: Submitting ResultStage 9 (ShuffledRDD[36] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,555 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 5.1 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,557 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,558 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.122.34:41057 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,559 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,560 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[36] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,560 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,565 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,585 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:44185 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,591 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.122.34:41786\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,687 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 123 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,687 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,688 INFO scheduler.DAGScheduler: ResultStage 9 (countByKey at ColumnProfiler.scala:592) finished in 0.139 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,689 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,689 INFO cluster.YarnScheduler: Killing all running tasks in stage 9: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:31,689 INFO scheduler.DAGScheduler: Job 6 finished: countByKey at ColumnProfiler.scala:592, took 2.392618 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,024 INFO scheduler.DAGScheduler: Registering RDD 41 (collect at AnalysisRunner.scala:326) as input to shuffle 3\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,024 INFO scheduler.DAGScheduler: Got map stage job 7 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,024 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 10 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,025 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,025 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,026 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[41] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,035 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 85.8 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,038 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 28.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,039 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.122.34:41057 (size: 28.1 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,040 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,040 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[41] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,040 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,042 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,059 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:44185 (size: 28.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,404 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 362 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,404 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,405 INFO scheduler.DAGScheduler: ShuffleMapStage 10 (collect at AnalysisRunner.scala:326) finished in 0.377 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,405 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,405 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,408 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,408 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,466 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,468 INFO scheduler.DAGScheduler: Got job 8 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,468 INFO scheduler.DAGScheduler: Final stage: ResultStage 12 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,468 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,468 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,469 INFO scheduler.DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[44] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,477 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 170.6 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,479 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 47.0 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,480 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.122.34:41057 (size: 47.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,481 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,481 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[44] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,481 INFO cluster.YarnScheduler: Adding task set 12.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,483 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 9) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,498 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:44185 (size: 47.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,518 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.0.122.34:41786\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,759 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 9) in 276 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,759 INFO cluster.YarnScheduler: Removed TaskSet 12.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,760 INFO scheduler.DAGScheduler: ResultStage 12 (collect at AnalysisRunner.scala:326) finished in 0.290 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,761 INFO scheduler.DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,761 INFO cluster.YarnScheduler: Killing all running tasks in stage 12: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,762 INFO scheduler.DAGScheduler: Job 8 finished: collect at AnalysisRunner.scala:326, took 0.295607 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:32,970 INFO codegen.CodeGenerator: Code generated in 34.230065 ms\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,031 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,032 INFO scheduler.DAGScheduler: Got job 9 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,032 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,032 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,032 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,034 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,053 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 38.3 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,055 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,056 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.122.34:41057 (size: 16.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,057 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,057 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,057 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,059 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,073 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:44185 (size: 16.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,511 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 452 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,514 INFO scheduler.DAGScheduler: ResultStage 13 (treeReduce at KLLRunner.scala:107) finished in 0.479 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,515 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,521 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,521 INFO cluster.YarnScheduler: Killing all running tasks in stage 13: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:33,522 INFO scheduler.DAGScheduler: Job 9 finished: treeReduce at KLLRunner.scala:107, took 0.491143 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,171 INFO codegen.CodeGenerator: Code generated in 46.7046 ms\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,180 INFO scheduler.DAGScheduler: Registering RDD 59 (collect at AnalysisRunner.scala:326) as input to shuffle 4\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,180 INFO scheduler.DAGScheduler: Got map stage job 10 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,181 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 14 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,181 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,181 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,187 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[59] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,191 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 35.0 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,194 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,195 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.122.34:41057 (size: 14.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,195 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,197 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[59] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,197 INFO cluster.YarnScheduler: Adding task set 14.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,199 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,213 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:44185 (size: 14.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,411 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 212 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,411 INFO cluster.YarnScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,413 INFO scheduler.DAGScheduler: ShuffleMapStage 14 (collect at AnalysisRunner.scala:326) finished in 0.224 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,414 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,415 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,415 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,415 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,608 INFO codegen.CodeGenerator: Code generated in 126.463726 ms\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,634 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,636 INFO scheduler.DAGScheduler: Got job 11 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,636 INFO scheduler.DAGScheduler: Final stage: ResultStage 16 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,637 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,637 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,638 INFO scheduler.DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,641 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 21.1 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,643 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,644 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.122.34:41057 (size: 8.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,645 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,646 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,646 INFO cluster.YarnScheduler: Adding task set 16.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,648 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 16.0 (TID 12) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,666 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:44185 (size: 8.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,674 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.122.34:41786\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,774 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 16.0 (TID 12) in 127 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,775 INFO cluster.YarnScheduler: Removed TaskSet 16.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,776 INFO scheduler.DAGScheduler: ResultStage 16 (collect at AnalysisRunner.scala:326) finished in 0.137 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,777 INFO scheduler.DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,777 INFO cluster.YarnScheduler: Killing all running tasks in stage 16: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,778 INFO scheduler.DAGScheduler: Job 11 finished: collect at AnalysisRunner.scala:326, took 0.142988 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,840 INFO codegen.CodeGenerator: Code generated in 47.842106 ms\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,981 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,982 INFO scheduler.DAGScheduler: Registering RDD 70 (countByKey at ColumnProfiler.scala:592) as input to shuffle 5\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,985 INFO scheduler.DAGScheduler: Got job 12 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,985 INFO scheduler.DAGScheduler: Final stage: ResultStage 18 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,985 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,985 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 17)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,987 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[70] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:34,999 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 32.9 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,003 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,005 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.122.34:41057 (size: 14.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,005 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,007 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[70] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,007 INFO cluster.YarnScheduler: Adding task set 17.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,013 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,023 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:44185 (size: 14.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,173 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 159 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,173 INFO cluster.YarnScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,174 INFO scheduler.DAGScheduler: ShuffleMapStage 17 (countByKey at ColumnProfiler.scala:592) finished in 0.186 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,175 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,175 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,175 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 18)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,176 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,176 INFO scheduler.DAGScheduler: Submitting ResultStage 18 (ShuffledRDD[71] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,179 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 5.1 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,181 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,181 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.122.34:41057 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,182 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,182 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (ShuffledRDD[71] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,182 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,184 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 14) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,198 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:44185 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,202 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.0.122.34:41786\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,222 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 14) in 37 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,224 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,225 INFO scheduler.DAGScheduler: ResultStage 18 (countByKey at ColumnProfiler.scala:592) finished in 0.048 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,226 INFO scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,226 INFO cluster.YarnScheduler: Killing all running tasks in stage 18: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,227 INFO scheduler.DAGScheduler: Job 12 finished: countByKey at ColumnProfiler.scala:592, took 0.245694 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,411 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:44185 in memory (size: 8.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,419 INFO scheduler.DAGScheduler: Registering RDD 76 (collect at AnalysisRunner.scala:326) as input to shuffle 6\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,419 INFO scheduler.DAGScheduler: Got map stage job 13 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,419 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 19 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,419 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,420 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.122.34:41057 in memory (size: 8.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,422 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,423 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[76] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,427 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:44185 in memory (size: 14.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,438 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.122.34:41057 in memory (size: 14.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,439 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 85.8 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,441 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 28.2 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,441 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.122.34:41057 (size: 28.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,442 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,443 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[76] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,443 INFO cluster.YarnScheduler: Adding task set 19.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,445 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,457 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.122.34:41057 in memory (size: 28.1 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,463 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:44185 (size: 28.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,463 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:44185 in memory (size: 28.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,507 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.122.34:41057 in memory (size: 14.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,510 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:44185 in memory (size: 14.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,558 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.122.34:41057 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,585 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:44185 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,637 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.122.34:41057 in memory (size: 14.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,645 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:44185 in memory (size: 14.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,699 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.122.34:41057 in memory (size: 28.1 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,734 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:44185 in memory (size: 28.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,780 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:44185 in memory (size: 47.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,785 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.122.34:41057 in memory (size: 47.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,828 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 383 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,829 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,830 INFO scheduler.DAGScheduler: ShuffleMapStage 19 (collect at AnalysisRunner.scala:326) finished in 0.406 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,830 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,831 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,831 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,831 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,872 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-1:44185 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,883 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.122.34:41057 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,896 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.122.34:41057 in memory (size: 16.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,899 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:44185 in memory (size: 16.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,905 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,906 INFO scheduler.DAGScheduler: Got job 14 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,906 INFO scheduler.DAGScheduler: Final stage: ResultStage 21 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,907 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,907 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,908 INFO scheduler.DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[79] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,915 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 170.7 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,917 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 47.0 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,924 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.122.34:41057 (size: 47.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,925 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,925 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[79] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,925 INFO cluster.YarnScheduler: Adding task set 21.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,927 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 21.0 (TID 16) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,944 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:44185 (size: 47.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:35,960 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.0.122.34:41786\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,001 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-1:44185 in memory (size: 47.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,009 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.122.34:41057 in memory (size: 47.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,112 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 21.0 (TID 16) in 185 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,112 INFO cluster.YarnScheduler: Removed TaskSet 21.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,113 INFO scheduler.DAGScheduler: ResultStage 21 (collect at AnalysisRunner.scala:326) finished in 0.204 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,114 INFO scheduler.DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,115 INFO cluster.YarnScheduler: Killing all running tasks in stage 21: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,115 INFO scheduler.DAGScheduler: Job 14 finished: collect at AnalysisRunner.scala:326, took 0.209862 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,185 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,188 INFO scheduler.DAGScheduler: Registering RDD 87 (countByKey at ColumnProfiler.scala:592) as input to shuffle 7\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,189 INFO scheduler.DAGScheduler: Got job 15 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,189 INFO scheduler.DAGScheduler: Final stage: ResultStage 23 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,189 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,189 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 22)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,190 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[87] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,198 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 32.9 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,201 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,203 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.122.34:41057 (size: 14.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,204 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,206 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[87] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,206 INFO cluster.YarnScheduler: Adding task set 22.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,208 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,218 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:44185 (size: 14.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,374 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 165 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,375 INFO cluster.YarnScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,376 INFO scheduler.DAGScheduler: ShuffleMapStage 22 (countByKey at ColumnProfiler.scala:592) finished in 0.185 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,376 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,377 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,378 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 23)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,378 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,378 INFO scheduler.DAGScheduler: Submitting ResultStage 23 (ShuffledRDD[88] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,381 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 5.1 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,382 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,383 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.122.34:41057 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,384 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,384 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (ShuffledRDD[88] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,385 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,386 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 18) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,401 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:44185 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,411 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.0.122.34:41786\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,435 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 18) in 49 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,435 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,436 INFO scheduler.DAGScheduler: ResultStage 23 (countByKey at ColumnProfiler.scala:592) finished in 0.057 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,436 INFO scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,437 INFO cluster.YarnScheduler: Killing all running tasks in stage 23: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,437 INFO scheduler.DAGScheduler: Job 15 finished: countByKey at ColumnProfiler.scala:592, took 0.251410 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,677 INFO scheduler.DAGScheduler: Registering RDD 93 (collect at AnalysisRunner.scala:326) as input to shuffle 8\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,677 INFO scheduler.DAGScheduler: Got map stage job 16 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,678 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,678 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,680 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,680 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[93] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,686 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 85.8 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,689 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 28.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,694 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.122.34:41057 (size: 28.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,695 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,698 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[93] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,698 INFO cluster.YarnScheduler: Adding task set 24.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,700 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 19) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:36,711 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:44185 (size: 28.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,065 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 19) in 366 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,065 INFO cluster.YarnScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,066 INFO scheduler.DAGScheduler: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326) finished in 0.385 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,066 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,066 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,066 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,067 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,123 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,124 INFO scheduler.DAGScheduler: Got job 17 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,125 INFO scheduler.DAGScheduler: Final stage: ResultStage 26 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,125 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,125 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,126 INFO scheduler.DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[96] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,142 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 170.5 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,145 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 46.9 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,145 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.122.34:41057 (size: 46.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,146 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,147 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[96] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,147 INFO cluster.YarnScheduler: Adding task set 26.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,148 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 20) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,161 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:44185 (size: 46.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,179 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.0.122.34:41786\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,443 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 20) in 295 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,444 INFO cluster.YarnScheduler: Removed TaskSet 26.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,446 INFO scheduler.DAGScheduler: ResultStage 26 (collect at AnalysisRunner.scala:326) finished in 0.318 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,449 INFO scheduler.DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,451 INFO cluster.YarnScheduler: Killing all running tasks in stage 26: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,451 INFO scheduler.DAGScheduler: Job 17 finished: collect at AnalysisRunner.scala:326, took 0.327606 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,585 INFO codegen.CodeGenerator: Code generated in 35.386798 ms\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,645 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,647 INFO scheduler.DAGScheduler: Got job 18 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,650 INFO scheduler.DAGScheduler: Final stage: ResultStage 27 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,651 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,651 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,652 INFO scheduler.DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[106] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,664 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 38.3 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,666 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,669 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.122.34:41057 (size: 16.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,671 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,672 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[106] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,672 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,677 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,689 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on algo-1:44185 (size: 16.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,957 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 281 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,957 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,962 INFO scheduler.DAGScheduler: ResultStage 27 (treeReduce at KLLRunner.scala:107) finished in 0.307 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,962 INFO scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,962 INFO cluster.YarnScheduler: Killing all running tasks in stage 27: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:37,962 INFO scheduler.DAGScheduler: Job 18 finished: treeReduce at KLLRunner.scala:107, took 0.316097 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,209 INFO scheduler.DAGScheduler: Registering RDD 111 (collect at AnalysisRunner.scala:326) as input to shuffle 9\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,209 INFO scheduler.DAGScheduler: Got map stage job 19 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,209 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 28 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,209 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,210 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,210 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[111] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,214 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 35.0 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,215 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,216 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.122.34:41057 (size: 14.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,216 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,217 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[111] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,217 INFO cluster.YarnScheduler: Adding task set 28.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,218 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 22) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,230 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on algo-1:44185 (size: 14.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,270 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 22) in 52 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,271 INFO cluster.YarnScheduler: Removed TaskSet 28.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,274 INFO scheduler.DAGScheduler: ShuffleMapStage 28 (collect at AnalysisRunner.scala:326) finished in 0.060 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,274 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,274 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,274 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,275 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,345 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,346 INFO scheduler.DAGScheduler: Got job 20 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,346 INFO scheduler.DAGScheduler: Final stage: ResultStage 30 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,347 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,347 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,347 INFO scheduler.DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[114] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,351 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 21.1 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,354 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,355 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.122.34:41057 (size: 8.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,357 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,362 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[114] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,362 INFO cluster.YarnScheduler: Adding task set 30.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,364 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 30.0 (TID 23) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,377 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on algo-1:44185 (size: 8.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,383 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.0.122.34:41786\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,389 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 30.0 (TID 23) in 26 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,390 INFO scheduler.DAGScheduler: ResultStage 30 (collect at AnalysisRunner.scala:326) finished in 0.041 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,391 INFO scheduler.DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,390 INFO cluster.YarnScheduler: Removed TaskSet 30.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,391 INFO cluster.YarnScheduler: Killing all running tasks in stage 30: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,392 INFO scheduler.DAGScheduler: Job 20 finished: collect at AnalysisRunner.scala:326, took 0.046545 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,512 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,527 INFO scheduler.DAGScheduler: Registering RDD 122 (countByKey at ColumnProfiler.scala:592) as input to shuffle 10\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,529 INFO scheduler.DAGScheduler: Got job 21 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,529 INFO scheduler.DAGScheduler: Final stage: ResultStage 32 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,529 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,530 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 31)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,532 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[122] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,540 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 32.9 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,541 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,544 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.122.34:41057 (size: 14.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,547 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,547 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[122] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,548 INFO cluster.YarnScheduler: Adding task set 31.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,549 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 24) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,563 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on algo-1:44185 (size: 14.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,716 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 24) in 167 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,716 INFO cluster.YarnScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,717 INFO scheduler.DAGScheduler: ShuffleMapStage 31 (countByKey at ColumnProfiler.scala:592) finished in 0.184 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,718 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,718 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,718 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 32)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,719 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,719 INFO scheduler.DAGScheduler: Submitting ResultStage 32 (ShuffledRDD[123] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,724 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 5.1 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,726 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,728 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.122.34:41057 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,729 INFO spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,730 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (ShuffledRDD[123] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,730 INFO cluster.YarnScheduler: Adding task set 32.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,733 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 25) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,742 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on algo-1:44185 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,747 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 10.0.122.34:41786\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,769 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 25) in 37 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,769 INFO cluster.YarnScheduler: Removed TaskSet 32.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,770 INFO scheduler.DAGScheduler: ResultStage 32 (countByKey at ColumnProfiler.scala:592) finished in 0.047 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,771 INFO scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,771 INFO cluster.YarnScheduler: Killing all running tasks in stage 32: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:38,772 INFO scheduler.DAGScheduler: Job 21 finished: countByKey at ColumnProfiler.scala:592, took 0.249325 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,211 INFO FileUtil: Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,268 INFO codegen.CodeGenerator: Code generated in 17.078022 ms\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,278 INFO scheduler.DAGScheduler: Registering RDD 128 (count at StatsGenerator.scala:66) as input to shuffle 11\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,278 INFO scheduler.DAGScheduler: Got map stage job 22 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,278 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 33 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,279 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,279 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,280 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[128] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,285 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 25.0 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,288 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,289 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.122.34:41057 (size: 11.1 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,290 INFO spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,291 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[128] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,291 INFO cluster.YarnScheduler: Adding task set 33.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,292 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 33.0 (TID 26) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,312 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on algo-1:44185 (size: 11.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,360 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 33.0 (TID 26) in 68 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,361 INFO cluster.YarnScheduler: Removed TaskSet 33.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,363 INFO scheduler.DAGScheduler: ShuffleMapStage 33 (count at StatsGenerator.scala:66) finished in 0.081 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,364 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,364 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,364 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,364 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,416 INFO codegen.CodeGenerator: Code generated in 34.87597 ms\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,491 INFO spark.SparkContext: Starting job: count at StatsGenerator.scala:66\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,494 INFO scheduler.DAGScheduler: Got job 23 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,495 INFO scheduler.DAGScheduler: Final stage: ResultStage 35 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,495 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,496 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,496 INFO scheduler.DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[131] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,501 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 11.1 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,511 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,512 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.122.34:41057 (size: 5.5 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,512 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on 10.0.122.34:41057 in memory (size: 8.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,513 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,513 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[131] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,514 INFO cluster.YarnScheduler: Adding task set 35.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,517 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 27) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,533 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on algo-1:44185 (size: 5.5 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,539 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 10.0.122.34:41786\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,541 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on algo-1:44185 in memory (size: 8.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,559 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 27) in 42 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,560 INFO scheduler.DAGScheduler: ResultStage 35 (count at StatsGenerator.scala:66) finished in 0.060 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,561 INFO scheduler.DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,561 INFO cluster.YarnScheduler: Removed TaskSet 35.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,562 INFO cluster.YarnScheduler: Killing all running tasks in stage 35: Stage finished\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,562 INFO scheduler.DAGScheduler: Job 23 finished: count at StatsGenerator.scala:66, took 0.071075 s\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,605 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on 10.0.122.34:41057 in memory (size: 16.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,607 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on algo-1:44185 in memory (size: 16.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,684 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-1:44185 in memory (size: 28.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,695 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.0.122.34:41057 in memory (size: 28.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,770 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on 10.0.122.34:41057 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,772 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on algo-1:44185 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,814 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.0.122.34:41057 in memory (size: 14.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,814 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on algo-1:44185 in memory (size: 14.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,833 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on 10.0.122.34:41057 in memory (size: 28.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,843 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on algo-1:44185 in memory (size: 28.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,878 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on 10.0.122.34:41057 in memory (size: 14.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,883 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on algo-1:44185 in memory (size: 14.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,923 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on 10.0.122.34:41057 in memory (size: 46.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,928 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on algo-1:44185 in memory (size: 46.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,963 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on algo-1:44185 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,971 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on 10.0.122.34:41057 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,996 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.0.122.34:41057 in memory (size: 11.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:39,997 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on algo-1:44185 in memory (size: 11.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,003 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.122.34:41057 in memory (size: 47.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,005 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on algo-1:44185 in memory (size: 47.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,011 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on 10.0.122.34:41057 in memory (size: 14.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,014 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on algo-1:44185 in memory (size: 14.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,068 INFO FileUtil: Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,085 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,136 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,137 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,144 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,169 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,218 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,218 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,223 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,236 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,307 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,307 INFO Main: Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,307 INFO Main: Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,328 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,329 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-8c44fc58-f9f8-46e4-9301-471a72f2c890\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,353 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-3c6cd3c1-72e8-4e21-a617-1e0cdf056413\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,482 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2025-10-20 12:09:40,483 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: yelp-rating-monitor-2025-10-20-12-10-58-124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring schedule created.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor, DatasetFormat, CronExpressionGenerator\n",
    "\n",
    "monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    base_job_name=\"yelp-rating-monitor\",\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "monitor.suggest_baseline(\n",
    "    baseline_dataset=raw_s3,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=f\"s3://{bucket}/{prefix}/monitoring/baseline\",\n",
    "    wait=True\n",
    ")\n",
    "\n",
    "monitor.create_monitoring_schedule(\n",
    "    endpoint_input=predictor.endpoint_name,\n",
    "    output_s3_uri=f\"s3://{bucket}/{prefix}/monitoring/reports\",\n",
    "    statistics=f\"s3://{bucket}/{prefix}/monitoring/baseline/statistics.json\",\n",
    "    constraints=f\"s3://{bucket}/{prefix}/monitoring/baseline/constraints.json\",\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    ")\n",
    "print(\"Monitoring schedule created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce214dc",
   "metadata": {},
   "source": [
    "## üßπ Cleanup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint()\n",
    "# monitor.delete_monitoring_schedule()\n",
    "# fg.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
